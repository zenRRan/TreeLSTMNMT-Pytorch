[Data]
data_dir = ch-en
train_files = %(data_dir)s/train.cn.dep %(data_dir)s/train.en
dev_files = %(data_dir)s/nist02.cn.dep %(data_dir)s/nist02.en0 %(data_dir)s/nist02.en1 %(data_dir)s/nist02.en2 %(data_dir)s/nist02.en3
test_files = %(data_dir)s/nist06.cn.dep %(data_dir)s/nist06.en0 %(data_dir)s/nist06.en1 %(data_dir)s/nist06.en2 %(data_dir)s/nist06.en3

[Save]
save_dir = ch-en-model
config_file = %(save_dir)s/config.cfg
save_model_path = %(save_dir)s/model
save_src_vocab_path = %(save_dir)s/src_vocab
save_tgt_vocab_path = %(save_dir)s/tgt_vocab
load_dir = ch-en-model
load_model_path = %(load_dir)s/model
load_src_vocab_path = %(load_dir)s/src_vocab
load_tgt_vocab_path = %(load_dir)s/tgt_vocab 

[Network]
vocab_size = 20000
num_layers = 1
embed_size = 512
rel_embed_size = 128
lstm_hidden_size = 1024
hidden_size = 1024
attention_size = 1024
dropout_emb = 0.0
dropout_lstm_input = 0.0
dropout_lstm_hidden = 0.0
dropout_hidden = 0.3
param_init = 0.08

[Optimizer]
learning_algorithm = adam
learning_rate = 0.0005
start_decay_at = 8
decay = 0.75
decay_steps = 5000
beta_1 = .9
beta_2 = .98
epsilon = 1e-12
clip = 5.0
max_patience = 1000
slow_start = 0.998

[Run]
train_iters = 50000
train_batch_size = 80
test_batch_size = 80
validate_every = 7200
update_every = 1
save_after = 1
decode_max_time_step = 100
max_train_length = 50
beam_size = 5
bleu_script = multi-bleu.pl
